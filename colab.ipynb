{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c12f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Google Driverのマウント\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79e8d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: No matching packages\u001b[0m\u001b[33m\n",
      "\u001b[0mFiles removed: 0\n"
     ]
    }
   ],
   "source": [
    "# ディスクの余分な容量を削除\n",
    "!pip cache purge\n",
    "!rm -rf /root/.local/share/Trash/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee5c9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         113G   39G   74G  35% /\n"
     ]
    }
   ],
   "source": [
    "# ディスク容量、他を確認\n",
    "!df -h /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2bd07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'HAR-2way-model'...\n",
      "remote: Enumerating objects: 237, done.\u001b[K\n",
      "remote: Counting objects: 100% (237/237), done.\u001b[K\n",
      "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
      "remote: Total 237 (delta 116), reused 210 (delta 92), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (237/237), 116.28 KiB | 2.47 MiB/s, done.\n",
      "Resolving deltas: 100% (116/116), done.\n",
      "/content/HAR-2way-model\n",
      "config_base.py\tdataset_builder  README.md  training\n"
     ]
    }
   ],
   "source": [
    "# HAR-2way-modelのクローンコピー\n",
    "!git clone https://github.com/JojiOkazaki/HAR-2way-model.git\n",
    "%cd HAR-2way-model\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265bc6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         113G   98G   15G  87% /\n",
      "/content/dataset:\n",
      "datasets\n",
      "\n",
      "/content/dataset/datasets:\n",
      "katorilab\n",
      "ucf101\n",
      "\n",
      "/content/dataset/datasets/katorilab:\n",
      "processed_112_32\n",
      "\n",
      "/content/dataset/datasets/katorilab/processed_112_32:\n",
      "pt\n",
      "splits\n",
      "\n",
      "/content/dataset/datasets/katorilab/processed_112_32/pt:\n",
      "20250802_094617.pt\n",
      "20250802_100426.pt\n",
      "20250802_101041.pt\n",
      "20250802_101506.pt\n",
      "20250802_102656.pt\n"
     ]
    }
   ],
   "source": [
    "# .zipの展開をしてデータセットの用意をする\n",
    "!mkdir -p /content/dataset\n",
    "!unzip -q \"/content/drive/MyDrive/HAR-2way-model/datas/datasets.zip\" -d /content/dataset\n",
    "!df -h /content\n",
    "!ls -R /content/dataset | head -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2571fe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.5.0\n",
      "  Downloading torch-2.5.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.0) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.0) (4.15.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.0) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.0) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.0)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.0)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.0)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch==2.5.0)\n",
      "  Downloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.0) (75.2.0)\n",
      "Collecting sympy==1.13.1 (from torch==2.5.0)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "  Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.22.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.20.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.0) (3.0.3)\n",
      "Downloading torch-2.5.0-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torchvision-0.20.0-cp312-cp312-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.5.0\n",
      "    Uninstalling triton-3.5.0:\n",
      "      Successfully uninstalled triton-3.5.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
      "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
      "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.9.0+cu126\n",
      "    Uninstalling torch-2.9.0+cu126:\n",
      "      Successfully uninstalled torch-2.9.0+cu126\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.24.0+cu126\n",
      "    Uninstalling torchvision-0.24.0+cu126:\n",
      "      Successfully uninstalled torchvision-0.24.0+cu126\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.0 torchvision-0.20.0 triton-3.1.0\n",
      "PyTorch Version: 2.5.0+cu124\n",
      "CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "# HAR-2way-model-trainingに必要なライブラリのインストール\n",
    "!pip install torch==2.5.0 torchvision pyyaml tqdm matplotlib\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "615c9655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config_local.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile config_local.py\n",
    "\n",
    "# config_local.py\n",
    "from pathlib import Path\n",
    "RAW_DATA_ROOT = Path(\"/content/dataset/\").resolve()\n",
    "DATASETS_ROOT = Path(RAW_DATA_ROOT / \"datasets\").resolve()\n",
    "DATASET_NAME = \"katorilab\"\n",
    "DATASET_ROOT = (DATASETS_ROOT / DATASET_NAME).resolve()\n",
    "ARTIFACT_ROOT = Path(\"/content/drive/MyDrive/HAR-2way-model/artifact\").resolve()\n",
    "\n",
    "TRAIN_RATIO = 0.58\n",
    "VAL_RATIO = 0.14\n",
    "TEST_RATIO = 0.29\n",
    "SPLIT_SEED = 42\n",
    "ENABLE_GROUP_BALANCE = True\n",
    "GROUP_BALANCE_ALPHA = 5.0\n",
    "\n",
    "# ファイルパスの存在チェック\n",
    "print(f\"Checking paths...\")\n",
    "print(f\"DATASET_ROOT exists: {DATASET_ROOT.exists()} ({DATASET_ROOT})\")\n",
    "# 例: katorilabの中身が見えるか確認\n",
    "if DATASET_ROOT.exists():\n",
    "    print(f\"Contents of {DATASET_NAME}: {[p.name for p in DATASET_ROOT.iterdir()]}\")\n",
    "\n",
    "assert DATASET_ROOT.exists(), f\"Error: {DATASET_ROOT} が見つかりません。解凍パスを確認してください。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "343b098a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training/configs/train.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile training/configs/train.yaml\n",
    "\n",
    "# train.yaml\n",
    "logging:\n",
    "  log_dir: runs\n",
    "  best_model_name: best_model.pt\n",
    "  csv_name: loss_history.csv\n",
    "  graph_dir: graphs\n",
    "  graph_size: [6, 4]\n",
    "\n",
    "dataset:\n",
    "  name: ucf101\n",
    "\n",
    "data:\n",
    "  processed_dir: processed_112_32\n",
    "  split: split01\n",
    "  # img_pt_dir: processed_112_32/pt\n",
    "  # skel_pt_dir: processed_112_32/pt\n",
    "  # train_file_list: processed_112_32/splits/default/train_list.txt\n",
    "  # val_file_list: processed_112_32/splits/default/val_list.txt\n",
    "  num_workers: 16\n",
    "\n",
    "weighted_sampler:\n",
    "  enabled: true\n",
    "  alpha: 1.0\n",
    "\n",
    "model:\n",
    "  architecture:\n",
    "    img:\n",
    "      cnn:\n",
    "        conv_channels: [3,16,32,64,128,256,256]\n",
    "        fc_layers: [256]\n",
    "        dropouts: [0.0,0.2,0.3,0.4,0.5,0.5]\n",
    "        input_size: [112, 112]\n",
    "      transformer:\n",
    "        d_model: 256\n",
    "        nhead: 8\n",
    "        num_layers: 3\n",
    "        dim_ff: 256\n",
    "        max_len: 32\n",
    "        dropout: 0.7\n",
    "\n",
    "    skel:\n",
    "      stgcn:\n",
    "        channels: [3,64,64,64,128,128,128,256,256,256]\n",
    "        dropouts: [0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3,0.3]\n",
    "        temporal_kernel_size: 9\n",
    "\n",
    "    mlp:\n",
    "      layers: [512, 512, 768]\n",
    "      dropouts: [0.4]\n",
    "\n",
    "  loss_weights: [1.0, 1.0, 1.0]\n",
    "\n",
    "training:\n",
    "  batch_size: 16\n",
    "  epochs: 120\n",
    "  accum_steps: 4\n",
    "  max_norm: 5.0 # 勾配が大きすぎないようにする。小さいと学習が遅くなり安定する。\n",
    "  seed: 42\n",
    "  patience: 5\n",
    "  min_delta: 0.005\n",
    "  recall_k: 1\n",
    "  \n",
    "  # proto_ce で学習（(A)）\n",
    "  loss_mode: proto_ce\n",
    "\n",
    "  # proto作成用の走査バッチ（VRAM節約で train batch と分けたい場合）\n",
    "  prototype_batch_size: 64\n",
    "\n",
    "  # valid人物判定（Trainer側で使う）\n",
    "  min_valid_t: 16\n",
    "\n",
    "  # unknown扱いしたい label_id（例: 999 を学習対象から外す）\n",
    "  unknown_label_ids: [999]\n",
    "\n",
    "  # proto_ce でも温度は使う（logitsのスケーリング）\n",
    "  temperature: 0.2\n",
    "\n",
    "optimizer:\n",
    "  lr: 0.0001 # 1e-3になると学習できない 0.0005 -> 0.001 (2倍)\n",
    "  weight_decay: 0.02\n",
    "  warmup_epochs: 1 # 学習の立ち上がりを遅くすることで序盤を安定させる。小さいと立ち上がりが速くなる。\n",
    "  min_lr_ratio: 0.1 # 学習後半で学習率を小さくすることで振動を安定させる。小さいと最終学習率が小さくなる。\n",
    "\n",
    "runtime:\n",
    "  device: cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd41f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb  3 10:03:52 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   32C    P0             45W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
      "\n",
      "\n",
      "\n",
      "               total        used        free      shared  buff/cache   available\n",
      "Mem:            83Gi       1.4Gi       5.7Gi       1.0Mi        76Gi        81Gi\n",
      "Swap:             0B          0B          0B\n",
      "\n",
      "\n",
      "\n",
      "Ubuntu 22.04.4 LTS \\n \\l\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "print(\"\\n\\n\")\n",
    "!cat /proc/cpuinfo | grep \"model name\" | head -n 1\n",
    "print(\"\\n\\n\")\n",
    "!free -h\n",
    "print(\"\\n\\n\")\n",
    "!cat /etc/issue\n",
    "print(\"\\n\\n\")\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f5243fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking paths...\n",
      "DATASET_ROOT exists: True (/content/dataset/datasets/katorilab)\n",
      "Contents of katorilab: ['processed_112_32']\n",
      "Create Data Loader...\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "elapsed time: 00:00:00\n",
      "Build class prototypes from train labels...\n",
      "elapsed time: 00:01:08\n",
      "Create Model...\n",
      "elapsed time: 00:00:00\n",
      "Training...\n",
      "  0% 0/477 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "100% 477/477 [02:03<00:00,  3.85it/s]\n",
      "100% 116/116 [00:24<00:00,  4.76it/s]\n",
      "[Epoch 1]acc:0.016/0.026 | main:13.739/13.446 | full:4.570/4.433 | img:4.603/4.518 | skel:4.565/4.496\n",
      "elapsed time: 00:02:29\n",
      "  0% 0/477 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "100% 477/477 [01:32<00:00,  5.14it/s]\n",
      "100% 116/116 [00:17<00:00,  6.57it/s]\n",
      "[Epoch 2]acc:\u001b[32m0.031\u001b[0m/\u001b[32m0.035\u001b[0m | main:\u001b[32m13.349\u001b[0m/\u001b[32m13.095\u001b[0m | full:\u001b[32m4.394\u001b[0m/\u001b[32m4.271\u001b[0m | img:\u001b[32m4.496\u001b[0m/\u001b[32m4.413\u001b[0m | skel:\u001b[32m4.458\u001b[0m/\u001b[32m4.410\u001b[0m\n",
      "elapsed time: 00:01:52\n",
      "100% 477/477 [01:30<00:00,  5.27it/s]\n",
      "100% 116/116 [00:15<00:00,  7.72it/s]\n",
      "[Epoch 3]acc:\u001b[32m0.040\u001b[0m/\u001b[32m0.045\u001b[0m | main:\u001b[32m13.108\u001b[0m/\u001b[32m12.981\u001b[0m | full:\u001b[32m4.291\u001b[0m/\u001b[32m4.236\u001b[0m | img:\u001b[32m4.432\u001b[0m/\u001b[32m4.357\u001b[0m | skel:\u001b[32m4.385\u001b[0m/\u001b[32m4.387\u001b[0m\n",
      "elapsed time: 00:01:46\n",
      "100% 477/477 [01:27<00:00,  5.46it/s]\n",
      "100% 116/116 [00:16<00:00,  6.83it/s]\n",
      "[Epoch 4]acc:\u001b[32m0.054\u001b[0m/\u001b[32m0.060\u001b[0m | main:\u001b[32m12.905\u001b[0m/\u001b[32m12.677\u001b[0m | full:\u001b[32m4.207\u001b[0m/\u001b[32m4.094\u001b[0m | img:\u001b[32m4.365\u001b[0m/\u001b[32m4.274\u001b[0m | skel:\u001b[32m4.333\u001b[0m/\u001b[32m4.308\u001b[0m\n",
      "elapsed time: 00:01:46\n",
      "100% 477/477 [01:27<00:00,  5.48it/s]\n",
      "100% 116/116 [00:18<00:00,  6.32it/s]\n",
      "[Epoch 5]acc:\u001b[32m0.064\u001b[0m/\u001b[31m0.057\u001b[0m | main:\u001b[32m12.750\u001b[0m/\u001b[32m12.613\u001b[0m | full:\u001b[32m4.139\u001b[0m/\u001b[32m4.062\u001b[0m | img:\u001b[32m4.321\u001b[0m/\u001b[32m4.258\u001b[0m | skel:\u001b[32m4.290\u001b[0m/\u001b[32m4.293\u001b[0m\n",
      "elapsed time: 00:01:47\n",
      "100% 477/477 [01:27<00:00,  5.48it/s]\n",
      "100% 116/116 [00:17<00:00,  6.65it/s]\n",
      "[Epoch 6]acc:\u001b[32m0.072\u001b[0m/\u001b[32m0.062\u001b[0m | main:\u001b[32m12.630\u001b[0m/\u001b[32m12.555\u001b[0m | full:\u001b[32m4.088\u001b[0m/\u001b[32m4.041\u001b[0m | img:\u001b[32m4.279\u001b[0m/\u001b[32m4.227\u001b[0m | skel:\u001b[32m4.263\u001b[0m/\u001b[32m4.287\u001b[0m\n",
      "elapsed time: 00:01:45\n",
      "100% 477/477 [01:26<00:00,  5.50it/s]\n",
      "100% 116/116 [00:14<00:00,  8.09it/s]\n",
      "[Epoch 7]acc:\u001b[32m0.082\u001b[0m/\u001b[32m0.077\u001b[0m | main:\u001b[32m12.521\u001b[0m/\u001b[32m12.380\u001b[0m | full:\u001b[32m4.042\u001b[0m/\u001b[32m3.965\u001b[0m | img:\u001b[32m4.246\u001b[0m/\u001b[32m4.190\u001b[0m | skel:\u001b[32m4.233\u001b[0m/\u001b[32m4.225\u001b[0m\n",
      "elapsed time: 00:01:42\n",
      "100% 477/477 [01:26<00:00,  5.49it/s]\n",
      "100% 116/116 [00:16<00:00,  7.10it/s]\n",
      "[Epoch 8]acc:\u001b[32m0.091\u001b[0m/\u001b[32m0.089\u001b[0m | main:\u001b[32m12.452\u001b[0m/\u001b[32m12.341\u001b[0m | full:\u001b[32m4.013\u001b[0m/\u001b[32m3.939\u001b[0m | img:\u001b[32m4.226\u001b[0m/\u001b[32m4.181\u001b[0m | skel:\u001b[32m4.213\u001b[0m/\u001b[32m4.222\u001b[0m\n",
      "elapsed time: 00:01:45\n",
      "100% 477/477 [01:27<00:00,  5.46it/s]\n",
      "100% 116/116 [00:17<00:00,  6.67it/s]\n",
      "[Epoch 9]acc:\u001b[32m0.096\u001b[0m/\u001b[32m0.102\u001b[0m | main:\u001b[32m12.365\u001b[0m/\u001b[32m12.245\u001b[0m | full:\u001b[32m3.976\u001b[0m/\u001b[32m3.901\u001b[0m | img:\u001b[32m4.199\u001b[0m/\u001b[32m4.139\u001b[0m | skel:\u001b[32m4.190\u001b[0m/\u001b[32m4.205\u001b[0m\n",
      "elapsed time: 00:01:46\n",
      "100% 477/477 [01:27<00:00,  5.47it/s]\n",
      "100% 116/116 [00:14<00:00,  7.89it/s]\n",
      "[Epoch 10]acc:\u001b[32m0.105\u001b[0m/\u001b[32m0.115\u001b[0m | main:\u001b[32m12.281\u001b[0m/\u001b[32m12.210\u001b[0m | full:\u001b[32m3.943\u001b[0m/\u001b[32m3.884\u001b[0m | img:\u001b[32m4.166\u001b[0m/\u001b[32m4.107\u001b[0m | skel:\u001b[32m4.172\u001b[0m/\u001b[31m4.219\u001b[0m\n",
      "elapsed time: 00:01:42\n",
      "100% 477/477 [01:27<00:00,  5.43it/s]\n",
      "100% 116/116 [00:15<00:00,  7.53it/s]\n",
      "[Epoch 11]acc:\u001b[32m0.111\u001b[0m/\u001b[31m0.108\u001b[0m | main:\u001b[32m12.205\u001b[0m/\u001b[32m12.208\u001b[0m | full:\u001b[32m3.911\u001b[0m/\u001b[32m3.882\u001b[0m | img:\u001b[32m4.141\u001b[0m/\u001b[31m4.141\u001b[0m | skel:\u001b[32m4.153\u001b[0m/\u001b[32m4.185\u001b[0m\n",
      "elapsed time: 00:01:44\n",
      "100% 477/477 [01:26<00:00,  5.50it/s]\n",
      "100% 116/116 [00:15<00:00,  7.25it/s]\n",
      "[Epoch 12]acc:\u001b[32m0.114\u001b[0m/\u001b[32m0.126\u001b[0m | main:\u001b[32m12.140\u001b[0m/\u001b[32m12.109\u001b[0m | full:\u001b[32m3.884\u001b[0m/\u001b[32m3.854\u001b[0m | img:\u001b[32m4.116\u001b[0m/\u001b[32m4.087\u001b[0m | skel:\u001b[32m4.140\u001b[0m/\u001b[32m4.168\u001b[0m\n",
      "elapsed time: 00:01:43\n",
      "100% 477/477 [01:26<00:00,  5.50it/s]\n",
      "100% 116/116 [00:14<00:00,  7.74it/s]\n",
      "[Epoch 13]acc:\u001b[32m0.123\u001b[0m/\u001b[31m0.115\u001b[0m | main:\u001b[32m12.077\u001b[0m/\u001b[32m12.035\u001b[0m | full:\u001b[32m3.860\u001b[0m/\u001b[32m3.816\u001b[0m | img:\u001b[32m4.088\u001b[0m/\u001b[32m4.056\u001b[0m | skel:\u001b[32m4.129\u001b[0m/\u001b[32m4.163\u001b[0m\n",
      "elapsed time: 00:01:42\n",
      "100% 477/477 [01:26<00:00,  5.53it/s]\n",
      "100% 116/116 [00:16<00:00,  6.91it/s]\n",
      "[Epoch 14]acc:\u001b[32m0.129\u001b[0m/\u001b[31m0.111\u001b[0m | main:\u001b[32m11.990\u001b[0m/\u001b[32m12.023\u001b[0m | full:\u001b[32m3.825\u001b[0m/\u001b[32m3.815\u001b[0m | img:\u001b[32m4.054\u001b[0m/\u001b[31m4.059\u001b[0m | skel:\u001b[32m4.110\u001b[0m/\u001b[32m4.149\u001b[0m\n",
      "elapsed time: 00:01:43\n",
      "100% 477/477 [01:25<00:00,  5.58it/s]\n",
      "100% 116/116 [00:14<00:00,  8.00it/s]\n",
      "[Epoch 15]acc:\u001b[32m0.133\u001b[0m/\u001b[32m0.138\u001b[0m | main:\u001b[32m11.915\u001b[0m/\u001b[32m11.890\u001b[0m | full:\u001b[32m3.794\u001b[0m/\u001b[32m3.762\u001b[0m | img:\u001b[32m4.023\u001b[0m/\u001b[32m4.020\u001b[0m | skel:\u001b[32m4.098\u001b[0m/\u001b[32m4.108\u001b[0m\n",
      "elapsed time: 00:01:40\n",
      "100% 477/477 [01:26<00:00,  5.54it/s]\n",
      "100% 116/116 [00:15<00:00,  7.66it/s]\n",
      "[Epoch 16]acc:\u001b[32m0.142\u001b[0m/\u001b[31m0.128\u001b[0m | main:\u001b[32m11.836\u001b[0m/\u001b[32m11.858\u001b[0m | full:\u001b[32m3.763\u001b[0m/\u001b[32m3.752\u001b[0m | img:\u001b[32m3.995\u001b[0m/\u001b[32m3.992\u001b[0m | skel:\u001b[32m4.077\u001b[0m/\u001b[31m4.114\u001b[0m\n",
      "elapsed time: 00:01:43\n",
      "100% 477/477 [01:27<00:00,  5.43it/s]\n",
      "100% 116/116 [00:17<00:00,  6.57it/s]\n",
      "[Epoch 17]acc:\u001b[32m0.144\u001b[0m/\u001b[32m0.133\u001b[0m | main:\u001b[32m11.772\u001b[0m/\u001b[32m11.791\u001b[0m | full:\u001b[32m3.736\u001b[0m/\u001b[32m3.729\u001b[0m | img:\u001b[32m3.961\u001b[0m/\u001b[32m3.972\u001b[0m | skel:\u001b[32m4.075\u001b[0m/\u001b[32m4.089\u001b[0m\n",
      "elapsed time: 00:01:46\n",
      "100% 477/477 [01:26<00:00,  5.51it/s]\n",
      "100% 116/116 [00:14<00:00,  8.04it/s]\n",
      "[Epoch 18]acc:\u001b[32m0.149\u001b[0m/\u001b[32m0.135\u001b[0m | main:\u001b[32m11.712\u001b[0m/\u001b[31m11.832\u001b[0m | full:\u001b[32m3.711\u001b[0m/\u001b[31m3.737\u001b[0m | img:\u001b[32m3.934\u001b[0m/\u001b[32m3.960\u001b[0m | skel:\u001b[32m4.066\u001b[0m/\u001b[31m4.135\u001b[0m\n",
      "elapsed time: 00:01:41\n",
      "100% 477/477 [01:26<00:00,  5.51it/s]\n",
      "100% 116/116 [00:15<00:00,  7.35it/s]\n",
      "[Epoch 19]acc:\u001b[32m0.153\u001b[0m/\u001b[32m0.143\u001b[0m | main:\u001b[32m11.629\u001b[0m/\u001b[32m11.758\u001b[0m | full:\u001b[32m3.677\u001b[0m/\u001b[32m3.702\u001b[0m | img:\u001b[32m3.902\u001b[0m/\u001b[32m3.934\u001b[0m | skel:\u001b[32m4.050\u001b[0m/\u001b[32m4.122\u001b[0m\n",
      "elapsed time: 00:01:44\n",
      "100% 477/477 [01:25<00:00,  5.59it/s]\n",
      "100% 116/116 [00:14<00:00,  7.85it/s]\n",
      "[Epoch 20]acc:\u001b[32m0.160\u001b[0m/\u001b[32m0.148\u001b[0m | main:\u001b[32m11.568\u001b[0m/\u001b[32m11.710\u001b[0m | full:\u001b[32m3.651\u001b[0m/\u001b[32m3.699\u001b[0m | img:\u001b[32m3.869\u001b[0m/\u001b[32m3.924\u001b[0m | skel:\u001b[32m4.048\u001b[0m/\u001b[32m4.087\u001b[0m\n",
      "elapsed time: 00:01:41\n",
      "100% 477/477 [01:26<00:00,  5.53it/s]\n",
      "100% 116/116 [00:14<00:00,  7.96it/s]\n",
      "[Epoch 21]acc:\u001b[32m0.160\u001b[0m/\u001b[32m0.153\u001b[0m | main:\u001b[32m11.505\u001b[0m/\u001b[32m11.672\u001b[0m | full:\u001b[32m3.623\u001b[0m/\u001b[32m3.677\u001b[0m | img:\u001b[32m3.846\u001b[0m/\u001b[32m3.920\u001b[0m | skel:\u001b[32m4.036\u001b[0m/\u001b[32m4.075\u001b[0m\n",
      "elapsed time: 00:01:41\n",
      "100% 477/477 [01:27<00:00,  5.48it/s]\n",
      "100% 116/116 [00:17<00:00,  6.46it/s]\n",
      "[Epoch 22]acc:\u001b[32m0.173\u001b[0m/\u001b[31m0.142\u001b[0m | main:\u001b[32m11.422\u001b[0m/\u001b[31m11.772\u001b[0m | full:\u001b[32m3.588\u001b[0m/\u001b[31m3.734\u001b[0m | img:\u001b[32m3.807\u001b[0m/\u001b[31m3.937\u001b[0m | skel:\u001b[32m4.027\u001b[0m/\u001b[31m4.101\u001b[0m\n",
      "elapsed time: 00:01:46\n",
      "100% 477/477 [01:26<00:00,  5.53it/s]\n",
      "100% 116/116 [00:16<00:00,  7.08it/s]\n",
      "[Epoch 23]acc:\u001b[32m0.178\u001b[0m/\u001b[32m0.162\u001b[0m | main:\u001b[32m11.342\u001b[0m/\u001b[32m11.634\u001b[0m | full:\u001b[32m3.556\u001b[0m/\u001b[32m3.674\u001b[0m | img:\u001b[32m3.773\u001b[0m/\u001b[32m3.894\u001b[0m | skel:\u001b[32m4.013\u001b[0m/\u001b[32m4.066\u001b[0m\n",
      "elapsed time: 00:01:43\n",
      "100% 477/477 [01:25<00:00,  5.55it/s]\n",
      "100% 116/116 [00:14<00:00,  7.99it/s]\n",
      "[Epoch 24]acc:\u001b[32m0.179\u001b[0m/\u001b[32m0.167\u001b[0m | main:\u001b[32m11.285\u001b[0m/\u001b[32m11.608\u001b[0m | full:\u001b[32m3.529\u001b[0m/\u001b[32m3.652\u001b[0m | img:\u001b[32m3.744\u001b[0m/\u001b[32m3.872\u001b[0m | skel:\u001b[32m4.012\u001b[0m/\u001b[31m4.083\u001b[0m\n",
      "elapsed time: 00:01:41\n",
      "100% 477/477 [01:28<00:00,  5.42it/s]\n",
      "100% 116/116 [00:15<00:00,  7.33it/s]\n",
      "[Epoch 25]acc:\u001b[32m0.196\u001b[0m/\u001b[31m0.161\u001b[0m | main:\u001b[32m11.178\u001b[0m/\u001b[32m11.531\u001b[0m | full:\u001b[32m3.482\u001b[0m/\u001b[32m3.634\u001b[0m | img:\u001b[32m3.700\u001b[0m/\u001b[32m3.854\u001b[0m | skel:\u001b[32m3.997\u001b[0m/\u001b[32m4.042\u001b[0m\n",
      "elapsed time: 00:01:45\n",
      "100% 477/477 [01:27<00:00,  5.45it/s]\n",
      "100% 116/116 [00:14<00:00,  7.99it/s]\n",
      "[Epoch 26]acc:\u001b[32m0.200\u001b[0m/\u001b[32m0.162\u001b[0m | main:\u001b[32m11.098\u001b[0m/\u001b[31m11.647\u001b[0m | full:\u001b[32m3.446\u001b[0m/\u001b[31m3.678\u001b[0m | img:\u001b[32m3.659\u001b[0m/\u001b[31m3.925\u001b[0m | skel:\u001b[32m3.993\u001b[0m/\u001b[31m4.044\u001b[0m\n",
      "elapsed time: 00:01:42\n",
      "100% 477/477 [01:26<00:00,  5.49it/s]\n",
      "100% 116/116 [00:14<00:00,  7.83it/s]\n",
      "[Epoch 27]acc:\u001b[32m0.212\u001b[0m/\u001b[32m0.178\u001b[0m | main:\u001b[32m11.017\u001b[0m/\u001b[32m11.477\u001b[0m | full:\u001b[32m3.411\u001b[0m/\u001b[32m3.614\u001b[0m | img:\u001b[32m3.621\u001b[0m/\u001b[32m3.828\u001b[0m | skel:\u001b[32m3.985\u001b[0m/\u001b[32m4.036\u001b[0m\n",
      "elapsed time: 00:01:43\n",
      "100% 477/477 [01:27<00:00,  5.48it/s]\n",
      "100% 116/116 [00:17<00:00,  6.66it/s]\n",
      "[Epoch 28]acc:\u001b[32m0.216\u001b[0m/\u001b[31m0.172\u001b[0m | main:\u001b[32m10.929\u001b[0m/\u001b[31m11.538\u001b[0m | full:\u001b[32m3.372\u001b[0m/\u001b[31m3.639\u001b[0m | img:\u001b[32m3.583\u001b[0m/\u001b[31m3.854\u001b[0m | skel:\u001b[32m3.974\u001b[0m/\u001b[31m4.045\u001b[0m\n",
      "elapsed time: 00:01:46\n",
      "100% 477/477 [01:27<00:00,  5.45it/s]\n",
      "100% 116/116 [00:14<00:00,  8.01it/s]\n",
      "[Epoch 29]acc:\u001b[32m0.226\u001b[0m/\u001b[32m0.184\u001b[0m | main:\u001b[32m10.858\u001b[0m/\u001b[32m11.476\u001b[0m | full:\u001b[32m3.339\u001b[0m/\u001b[32m3.616\u001b[0m | img:\u001b[32m3.552\u001b[0m/\u001b[32m3.834\u001b[0m | skel:\u001b[32m3.967\u001b[0m/\u001b[32m4.026\u001b[0m\n",
      "elapsed time: 00:01:42\n",
      "100% 477/477 [01:26<00:00,  5.50it/s]\n",
      "100% 116/116 [00:15<00:00,  7.28it/s]\n",
      "[Epoch 30]acc:\u001b[32m0.230\u001b[0m/\u001b[32m0.191\u001b[0m | main:\u001b[32m10.799\u001b[0m/\u001b[32m11.435\u001b[0m | full:\u001b[32m3.311\u001b[0m/\u001b[32m3.606\u001b[0m | img:\u001b[32m3.526\u001b[0m/\u001b[32m3.820\u001b[0m | skel:\u001b[32m3.962\u001b[0m/\u001b[32m4.009\u001b[0m\n",
      "elapsed time: 00:01:44\n",
      "100% 477/477 [01:27<00:00,  5.48it/s]\n",
      "100% 116/116 [00:17<00:00,  6.69it/s]\n",
      "[Epoch 31]acc:\u001b[32m0.242\u001b[0m/\u001b[31m0.187\u001b[0m | main:\u001b[32m10.698\u001b[0m/\u001b[31m11.458\u001b[0m | full:\u001b[32m3.265\u001b[0m/\u001b[31m3.611\u001b[0m | img:\u001b[32m3.483\u001b[0m/\u001b[31m3.824\u001b[0m | skel:\u001b[32m3.950\u001b[0m/\u001b[31m4.022\u001b[0m\n",
      "elapsed time: 00:01:45\n",
      "100% 477/477 [01:26<00:00,  5.49it/s]\n",
      "100% 116/116 [00:14<00:00,  7.83it/s]\n",
      "[Epoch 32]acc:\u001b[32m0.244\u001b[0m/\u001b[32m0.189\u001b[0m | main:\u001b[32m10.645\u001b[0m/\u001b[32m11.414\u001b[0m | full:\u001b[32m3.241\u001b[0m/\u001b[32m3.600\u001b[0m | img:\u001b[32m3.458\u001b[0m/\u001b[32m3.821\u001b[0m | skel:\u001b[32m3.946\u001b[0m/\u001b[32m3.993\u001b[0m\n",
      "elapsed time: 00:01:42\n",
      "100% 477/477 [01:26<00:00,  5.49it/s]\n",
      "100% 116/116 [00:15<00:00,  7.31it/s]\n",
      "[Epoch 33]acc:\u001b[32m0.257\u001b[0m/\u001b[31m0.163\u001b[0m | main:\u001b[32m10.550\u001b[0m/\u001b[31m11.484\u001b[0m | full:\u001b[32m3.199\u001b[0m/\u001b[31m3.641\u001b[0m | img:\u001b[32m3.418\u001b[0m/\u001b[31m3.848\u001b[0m | skel:\u001b[32m3.933\u001b[0m/\u001b[31m3.995\u001b[0m\n",
      "elapsed time: 00:01:44\n",
      "100% 477/477 [01:27<00:00,  5.48it/s]\n",
      "100% 116/116 [00:14<00:00,  7.89it/s]\n",
      "[Epoch 34]acc:\u001b[32m0.264\u001b[0m/\u001b[32m0.178\u001b[0m | main:\u001b[32m10.500\u001b[0m/\u001b[32m11.407\u001b[0m | full:\u001b[32m3.171\u001b[0m/\u001b[32m3.600\u001b[0m | img:\u001b[32m3.394\u001b[0m/\u001b[32m3.819\u001b[0m | skel:\u001b[31m3.935\u001b[0m/\u001b[32m3.989\u001b[0m\n",
      "elapsed time: 00:01:42\n",
      "100% 477/477 [01:26<00:00,  5.50it/s]\n",
      "100% 116/116 [00:14<00:00,  7.96it/s]\n",
      "[Epoch 35]acc:\u001b[32m0.269\u001b[0m/\u001b[32m0.200\u001b[0m | main:\u001b[32m10.424\u001b[0m/\u001b[32m11.364\u001b[0m | full:\u001b[32m3.137\u001b[0m/\u001b[32m3.583\u001b[0m | img:\u001b[32m3.359\u001b[0m/\u001b[32m3.788\u001b[0m | skel:\u001b[32m3.928\u001b[0m/\u001b[31m3.993\u001b[0m\n",
      "elapsed time: 00:01:42\n",
      "100% 477/477 [01:25<00:00,  5.60it/s]\n",
      "100% 116/116 [00:16<00:00,  6.94it/s]\n",
      "[Epoch 36]acc:\u001b[32m0.270\u001b[0m/\u001b[32m0.201\u001b[0m | main:\u001b[32m10.342\u001b[0m/\u001b[32m11.353\u001b[0m | full:\u001b[32m3.099\u001b[0m/\u001b[31m3.583\u001b[0m | img:\u001b[32m3.324\u001b[0m/\u001b[32m3.788\u001b[0m | skel:\u001b[32m3.919\u001b[0m/\u001b[32m3.982\u001b[0m\n",
      "elapsed time: 00:01:42\n",
      "100% 477/477 [01:25<00:00,  5.58it/s]\n",
      "100% 116/116 [00:13<00:00,  8.31it/s]\n",
      "[Epoch 37]acc:\u001b[32m0.289\u001b[0m/\u001b[31m0.195\u001b[0m | main:\u001b[32m10.264\u001b[0m/\u001b[31m11.455\u001b[0m | full:\u001b[32m3.064\u001b[0m/\u001b[31m3.622\u001b[0m | img:\u001b[32m3.291\u001b[0m/\u001b[31m3.816\u001b[0m | skel:\u001b[32m3.910\u001b[0m/\u001b[31m4.017\u001b[0m\n",
      "elapsed time: 00:01:40\n",
      "100% 477/477 [01:26<00:00,  5.52it/s]\n",
      "100% 116/116 [00:16<00:00,  7.22it/s]\n",
      "[Epoch 38]acc:\u001b[32m0.293\u001b[0m/\u001b[32m0.201\u001b[0m | main:\u001b[32m10.225\u001b[0m/\u001b[32m11.331\u001b[0m | full:\u001b[32m3.046\u001b[0m/\u001b[32m3.569\u001b[0m | img:\u001b[32m3.277\u001b[0m/\u001b[32m3.765\u001b[0m | skel:\u001b[32m3.902\u001b[0m/\u001b[32m3.998\u001b[0m\n",
      "elapsed time: 00:01:44\n",
      "100% 477/477 [01:25<00:00,  5.56it/s]\n",
      "100% 116/116 [00:14<00:00,  8.07it/s]\n",
      "[Epoch 39]acc:\u001b[32m0.296\u001b[0m/\u001b[31m0.195\u001b[0m | main:\u001b[32m10.141\u001b[0m/\u001b[31m11.338\u001b[0m | full:\u001b[32m3.005\u001b[0m/\u001b[31m3.584\u001b[0m | img:\u001b[32m3.241\u001b[0m/\u001b[31m3.793\u001b[0m | skel:\u001b[32m3.895\u001b[0m/\u001b[32m3.961\u001b[0m\n",
      "elapsed time: 00:01:41\n",
      "100% 477/477 [01:25<00:00,  5.55it/s]\n",
      "100% 116/116 [00:14<00:00,  7.93it/s]\n",
      "[Epoch 40]acc:\u001b[32m0.308\u001b[0m/\u001b[32m0.212\u001b[0m | main:\u001b[32m10.062\u001b[0m/\u001b[32m11.288\u001b[0m | full:\u001b[32m2.968\u001b[0m/\u001b[32m3.556\u001b[0m | img:\u001b[32m3.205\u001b[0m/\u001b[32m3.768\u001b[0m | skel:\u001b[32m3.889\u001b[0m/\u001b[31m3.965\u001b[0m\n",
      "elapsed time: 00:01:42\n",
      "100% 477/477 [01:25<00:00,  5.57it/s]\n",
      "100% 116/116 [00:17<00:00,  6.48it/s]\n",
      "[Epoch 41]acc:\u001b[32m0.319\u001b[0m/\u001b[32m0.217\u001b[0m | main:\u001b[32m10.006\u001b[0m/\u001b[32m11.227\u001b[0m | full:\u001b[32m2.943\u001b[0m/\u001b[32m3.531\u001b[0m | img:\u001b[32m3.182\u001b[0m/\u001b[32m3.732\u001b[0m | skel:\u001b[32m3.882\u001b[0m/\u001b[32m3.964\u001b[0m\n",
      "elapsed time: 00:01:45\n",
      "100% 477/477 [01:26<00:00,  5.52it/s]\n",
      "100% 116/116 [00:14<00:00,  8.20it/s]\n",
      "[Epoch 42]acc:\u001b[32m0.320\u001b[0m/\u001b[31m0.213\u001b[0m | main:\u001b[32m9.942\u001b[0m/\u001b[31m11.243\u001b[0m | full:\u001b[32m2.915\u001b[0m/\u001b[31m3.546\u001b[0m | img:\u001b[32m3.153\u001b[0m/\u001b[31m3.749\u001b[0m | skel:\u001b[32m3.875\u001b[0m/\u001b[32m3.949\u001b[0m\n",
      "elapsed time: 00:01:41\n",
      "100% 477/477 [01:25<00:00,  5.57it/s]\n",
      "100% 116/116 [00:14<00:00,  8.00it/s]\n",
      "[Epoch 43]acc:\u001b[32m0.339\u001b[0m/\u001b[32m0.227\u001b[0m | main:\u001b[32m9.882\u001b[0m/\u001b[32m11.203\u001b[0m | full:\u001b[32m2.885\u001b[0m/\u001b[32m3.528\u001b[0m | img:\u001b[32m3.126\u001b[0m/\u001b[32m3.737\u001b[0m | skel:\u001b[32m3.871\u001b[0m/\u001b[32m3.938\u001b[0m\n",
      "elapsed time: 00:01:41\n",
      "100% 477/477 [01:26<00:00,  5.53it/s]\n",
      "100% 116/116 [00:17<00:00,  6.80it/s]\n",
      "[Epoch 44]acc:\u001b[31m0.335\u001b[0m/\u001b[31m0.201\u001b[0m | main:\u001b[32m9.831\u001b[0m/\u001b[31m11.349\u001b[0m | full:\u001b[32m2.858\u001b[0m/\u001b[31m3.610\u001b[0m | img:\u001b[32m3.102\u001b[0m/\u001b[31m3.802\u001b[0m | skel:\u001b[31m3.871\u001b[0m/\u001b[32m3.938\u001b[0m\n",
      "elapsed time: 00:01:44\n",
      "100% 477/477 [01:25<00:00,  5.61it/s]\n",
      "100% 116/116 [00:14<00:00,  8.06it/s]\n",
      "[Epoch 45]acc:\u001b[32m0.344\u001b[0m/\u001b[32m0.220\u001b[0m | main:\u001b[32m9.769\u001b[0m/\u001b[32m11.227\u001b[0m | full:\u001b[32m2.830\u001b[0m/\u001b[32m3.531\u001b[0m | img:\u001b[32m3.077\u001b[0m/\u001b[32m3.726\u001b[0m | skel:\u001b[32m3.862\u001b[0m/\u001b[31m3.970\u001b[0m\n",
      "elapsed time: 00:01:40\n",
      "100% 477/477 [01:26<00:00,  5.52it/s]\n",
      "100% 116/116 [00:14<00:00,  7.77it/s]\n",
      "[Epoch 46]acc:\u001b[32m0.358\u001b[0m/\u001b[31m0.213\u001b[0m | main:\u001b[32m9.690\u001b[0m/\u001b[31m11.288\u001b[0m | full:\u001b[32m2.795\u001b[0m/\u001b[31m3.578\u001b[0m | img:\u001b[32m3.046\u001b[0m/\u001b[31m3.775\u001b[0m | skel:\u001b[32m3.850\u001b[0m/\u001b[32m3.935\u001b[0m\n",
      "elapsed time: 00:01:42\n",
      "100% 477/477 [01:25<00:00,  5.59it/s]\n",
      "100% 116/116 [00:17<00:00,  6.67it/s]\n",
      "[Epoch 47]acc:\u001b[32m0.365\u001b[0m/\u001b[32m0.217\u001b[0m | main:\u001b[32m9.632\u001b[0m/\u001b[32m11.234\u001b[0m | full:\u001b[32m2.768\u001b[0m/\u001b[32m3.552\u001b[0m | img:\u001b[32m3.022\u001b[0m/\u001b[32m3.748\u001b[0m | skel:\u001b[32m3.843\u001b[0m/\u001b[32m3.934\u001b[0m\n",
      "elapsed time: 00:01:43\n",
      "100% 477/477 [01:25<00:00,  5.56it/s]\n",
      "100% 116/116 [00:14<00:00,  8.13it/s]\n",
      "[Epoch 48]acc:\u001b[32m0.373\u001b[0m/\u001b[31m0.210\u001b[0m | main:\u001b[32m9.566\u001b[0m/\u001b[31m11.342\u001b[0m | full:\u001b[32m2.736\u001b[0m/\u001b[31m3.598\u001b[0m | img:\u001b[32m2.990\u001b[0m/\u001b[31m3.784\u001b[0m | skel:\u001b[32m3.840\u001b[0m/\u001b[31m3.959\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m training.main --config training/configs/train.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
