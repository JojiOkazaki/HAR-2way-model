logging:
  log_dir: runs
  best_model_name: best_model.pt
  csv_name: loss_history.csv
  graph_dir: graphs
  graph_size: [6, 4]

dataset:
  name: katorilab

data:
  processed_dir: processed_112_32
  split: default
  # img_pt_dir: processed_112_32/pt
  # skel_pt_dir: processed_112_32/pt
  # train_file_list: processed_112_32/splits/default/train_list.txt
  # val_file_list: processed_112_32/splits/default/val_list.txt
  num_workers: 16

model:
  architecture:
    img:
      cnn:
        conv_channels: [3, 16, 32, 64]
        fc_layers: [128]
        dropouts: [0.0, 0.2, 0.3]
        input_size: [112, 112]
      transformer:
        d_model: 128
        nhead: 8
        num_layers: 2
        dim_ff: 256
        max_len: 32
        dropout: 0.3

    skel:
      stgcn:
        channels: [3, 16, 32, 64, 128]
        dropouts: [0.0, 0.0, 0.1, 0.2]
        temporal_kernel_size: 9

    mlp:
      layers: [256, 512, 768]
      dropouts: [0.4]

  loss_weights: [1.0, 1.0, 1.0]

training:
  batch_size: 6
  epochs: 120
  accum_steps: 1
  max_norm: 5.0 # 勾配が大きすぎないようにする。小さいと学習が遅くなり安定する。
  seed: 42
  patience: 10
  min_delta: 0.001
  recall_k: 1
  temperature: 0.2 # 大きくするとrecallが伸びる

optimizer:
  lr: 0.0001 # 1e-3になると学習できない 0.0005 -> 0.001 (2倍)
  weight_decay: 0.01
  warmup_epochs: 1 # 学習の立ち上がりを遅くすることで序盤を安定させる。小さいと立ち上がりが速くなる。
  min_lr_ratio: 0.5 # 学習後半で学習率を小さくすることで振動を安定させる。小さいと最終学習率が小さくなる。

runtime:
  device: cuda

finetune:
  init_checkpoint: runs/20260201183125/20260201183125_best_model.pt
  strict: true
  freeze_prefixes: []   # 例: ["image_branch.cnn", "skeleton_branch"] など
