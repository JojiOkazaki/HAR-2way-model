logging:
  log_dir: runs
  best_model_name: best_model.pt
  csv_name: loss_history.csv
  graph_dir: graphs
  graph_size: [6, 4]

data:
  img_pt_dir: processed/pt
  skel_pt_dir: processed/pt
  train_file_list: processed/splits/train_list.txt
  val_file_list: processed/splits/val_list.txt
  num_workers: 14

model:
  architecture:
    img:
      cnn:
        conv_channels: [3, 16, 32, 64]
        fc_layers: [128]
        dropouts: [0.15, 0.15, 0.4]
        input_size: [112, 112]
      transformer:
        d_model: 128
        nhead: 8
        num_layers: 2
        dim_ff: 256
        max_len: 32
        dropout: 0.5

    skel:
      stgcn:
        channels: [3, 64, 64, 64, 128, 128, 128, 256, 256, 128]
        dropouts: [0.1, 0.2, 0.3, 0.4, 0.4, 0.4, 0.5, 0.5, 0.5]
        temporal_kernel_size: 9

    mlp:
      layers: [256, 128, 768]
      dropouts: [0.3]

  loss_weights: [1.0, 0.5, 0.25]

training:
  batch_size: 4
  epochs: 100
  accum_steps: 3
  max_norm: 5.0 # 勾配が大きすぎないようにする。小さいと学習が遅くなり安定する。
  seed: 42
  patience: 50
  min_delta: 0.0001
  recall_k: 3
  temperature: 0.1 # 大きくするとrecallが伸びる

optimizer:
  lr: 0.0005 # 1e-3になると学習できない 0.0005 -> 0.001 (2倍)
  weight_decay: 0.001
  warmup_epochs: 1 # 学習の立ち上がりを遅くすることで序盤を安定させる。小さいと立ち上がりが速くなる。
  min_lr_ratio: 0.1 # 学習後半で学習率を小さくすることで振動を安定させる。小さいと最終学習率が小さくなる。

runtime:
  device: cuda

#preprocess:
#  img_aug:
#    p: 0.4
#    jitter: 0.1
#    hue: 0.02
#    noise_std: 0.01
#    p_erasing: 0.0
#    erasing_scale: [0.02, 0.10]



# バッチサイズ8: 3.9->4.9GB
# バッチサイズ9: 3.9->
# バッチサイズ12: 4.9->
# バッチサイズ16: 6.9->7.7(ギリギリ共有使ってるかも)